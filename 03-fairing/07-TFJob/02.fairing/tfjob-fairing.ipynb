{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 210314 19:02:00 config:134] Using preprocessor: <kubeflow.fairing.preprocessors.converted_notebook.ConvertNotebookPreprocessor object at 0x7f8de7257940>\n",
      "[I 210314 19:02:00 config:136] Using builder: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f8de72579e8>\n",
      "[I 210314 19:02:00 config:138] Using deployer: <kubeflow.fairing.deployers.tfjob.tfjob.TfJob object at 0x7f8de7257908>\n",
      "[W 210314 19:02:00 append:50] Building image using Append builder...\n",
      "[I 210314 19:02:00 base:107] Creating docker context: /tmp/fairing_context_3dnv6f9e\n",
      "[I 210314 19:02:00 converted_notebook:127] Converting mnist-dist.ipynb to mnist-dist.py\n",
      "[I 210314 19:02:00 docker_creds_:234] Loading Docker credentials for repository 'reddiana/mybase'\n",
      "[W 210314 19:02:01 append:54] Image successfully built in 1.0435814910015324s.\n",
      "[W 210314 19:02:01 append:94] Pushing image registry.kube-system.svc.cluster.local:30000/tfjob-fairing-mnist:9155B049...\n",
      "[I 210314 19:02:01 docker_creds_:234] Loading Docker credentials for repository 'registry.kube-system.svc.cluster.local:30000/tfjob-fairing-mnist:9155B049'\n",
      "[W 210314 19:02:01 append:81] Uploading registry.kube-system.svc.cluster.local:30000/tfjob-fairing-mnist:9155B049\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:0b2b6f75fc9510d3889bb224823a6d8a720a0cba6d7481874e4612ccbccd3014 exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:cce7189e3c4a62a5a399aa938aec6b8ea962801556ba25c48734f668a2358e80 exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:b3afe92c540b778c64ca316d1e679d55d2d2e812e450f516a808ee591f0c3f77 exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:b0e37080d99216149043f62e7cca07b02ac51f5965377e957d019d5872b83062 exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:d22d2dfcfa9cd230ed3c47defec2670d45081598c721dd85cafc34ea459f970e exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:961442e8e0e4f9ec91ef34f41523a3dc42e68476b5f8d27e2fe43f179d801263 exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:1f0ffb4d2509e58e040b2d3c146f875dfc5d39ac9e974e6bfb1a5505b98eefae exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:d519e2592276828ca171d85e0532899cd4f98c70f5c697b45fa2e126e9f9fe49 exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:e266fced02fae9320dafe0ef2adab0fd0bdd5a7d795848c2fa344eafb4f70ab9 exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:c12ceea561ed13e6b0566ce331de9cfc90b43ab4b14a2e12a5a29d73420f51b3 exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:c29b15b084af0bc2cabab123e72a62f1d9919774f15a91eeeb3b138aaf5f7850 exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:280] Layer sha256:5d43e8c7056a20768e9c36d57ba56227f71df1563d630d424f512efd7b028805 exists, skipping\n",
      "[I 210314 19:02:01 docker_session_:284] Layer sha256:55d1ada2db86a6fe6d4ff92966e963fc3e1079eeeebe044d66ad6871b2b4737b pushed.\n",
      "[I 210314 19:02:01 docker_session_:334] Finished upload of: registry.kube-system.svc.cluster.local:30000/tfjob-fairing-mnist:9155B049\n",
      "[W 210314 19:02:01 append:99] Pushed image registry.kube-system.svc.cluster.local:30000/tfjob-fairing-mnist:9155B049 in 0.11444720700092148s.\n",
      "[W 210314 19:02:01 job:101] The tfjob my-mnist-745b0512 launched.\n",
      "[W 210314 19:02:01 manager:298] Waiting for my-mnist-745b0512-worker-0 to start...\n",
      "[W 210314 19:02:01 manager:298] Waiting for my-mnist-745b0512-worker-0 to start...\n",
      "[W 210314 19:02:01 manager:298] Waiting for my-mnist-745b0512-worker-0 to start...\n",
      "[I 210314 19:02:04 manager:304] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-14 19:02:04.030050: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-03-14 19:02:04.030100: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:00<00:00,  4.13 file/s]\n",
      "WARNING:tensorflow:From /app/mnist-dist.py:77: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use distribute.MultiWorkerMirroredStrategy instead\n",
      "WARNING:tensorflow:From /app/mnist-dist.py:77: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use distribute.MultiWorkerMirroredStrategy instead\n",
      "2021-03-14 19:02:11.240393: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-03-14 19:02:11.240847: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-03-14 19:02:11.240932: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-03-14 19:02:11.240995: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (my-mnist-745b0512-worker-0): /proc/driver/nvidia/version does not exist\n",
      "2021-03-14 19:02:11.241987: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-14 19:02:11.242405: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-03-14 19:02:11.243175: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-03-14 19:02:11.298995: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job chief -> {0 -> my-mnist-745b0512-chief-0.myspace.svc:2222}\n",
      "2021-03-14 19:02:11.299047: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> my-mnist-745b0512-worker-0.myspace.svc:2222, 1 -> my-mnist-745b0512-worker-1.myspace.svc:2222}\n",
      "2021-03-14 19:02:11.300118: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://my-mnist-745b0512-worker-0.myspace.svc:2222\n",
      "2021-03-14 19:02:12.528393: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-03-14 19:02:12.528446: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-03-14 19:02:12.528506: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-03-14 19:02:12.942626: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-03-14 19:02:12.943232: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
      "2021-03-14 19:02:26.511694: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 24535 of 50000\n",
      "2021-03-14 19:02:36.596895: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 49557 of 50000\n",
      "2021-03-14 19:02:36.725237: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:230] Shuffle buffer filled.\n",
      "TensorFlow version:  2.4.1\n",
      "TF_CONFIG [{\"cluster\":{\"chief\":[\"my-mnist-745b0512-chief-0.myspace.svc:2222\"],\"worker\":[\"my-mnist-745b0512-worker-0.myspace.svc:2222\",\"my-mnist-745b0512-worker-1.myspace.svc:2222\"]},\"task\":{\"type\":\"worker\",\"index\":0},\"environment\":\"cloud\"}]\n",
      "cluster=[{'chief': ['my-mnist-745b0512-chief-0.myspace.svc:2222'], 'worker': ['my-mnist-745b0512-worker-0.myspace.svc:2222', 'my-mnist-745b0512-worker-1.myspace.svc:2222']}] job_name=[worker] task_index=[0]\n",
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to ./dataset/mnist/3.0.1...\u001b[0m\n",
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to ./dataset/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "Training...\n",
      "Epoch 1/3\n",
      "2021-03-14 19:02:37.017665: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-03-14 19:02:37.017717: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-03-14 19:02:37.035996: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-03-14 19:02:37.039028: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-03-14 19:02:37.043259: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/workertemp_0/train/plugins/profile/2021_03_14_19_02_37\n",
      "2021-03-14 19:02:37.044509: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs/workertemp_0/train/plugins/profile/2021_03_14_19_02_37/my-mnist-745b0512-worker-0.trace.json.gz\n",
      "2021-03-14 19:02:37.048662: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/workertemp_0/train/plugins/profile/2021_03_14_19_02_37\n",
      "2021-03-14 19:02:37.048912: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs/workertemp_0/train/plugins/profile/2021_03_14_19_02_37/my-mnist-745b0512-worker-0.memory_profile.json.gz\n",
      "2021-03-14 19:02:37.096469: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/workertemp_0/train/plugins/profile/2021_03_14_19_02_37Dumped tool data for xplane.pb to ./logs/workertemp_0/train/plugins/profile/2021_03_14_19_02_37/my-mnist-745b0512-worker-0.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/workertemp_0/train/plugins/profile/2021_03_14_19_02_37/my-mnist-745b0512-worker-0.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/workertemp_0/train/plugins/profile/2021_03_14_19_02_37/my-mnist-745b0512-worker-0.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/workertemp_0/train/plugins/profile/2021_03_14_19_02_37/my-mnist-745b0512-worker-0.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/workertemp_0/train/plugins/profile/2021_03_14_19_02_37/my-mnist-745b0512-worker-0.kernel_stats.pb\n",
      "\n",
      " 11/937 [..............................] - ETA: 46s - loss: 2.1837 - accuracy: 0.2562   \n",
      " 25/937 [..............................] - ETA: 42s - loss: 1.9400 - accuracy: 0.389\n",
      " 39/937 [>.............................] - ETA: 40s - loss: 1.7536 - accuracy: 0.458\n",
      " 54/937 [>.............................] - ETA: 38s - loss: 1.6004 - accuracy: 0.517\n",
      " 69/937 [=>............................] - ETA: 37s - loss: 1.4806 - accuracy: 0.557\n",
      " 83/937 [=>............................] - ETA: 36s - loss: 1.3917 - accuracy: 0.580\n",
      " 98/937 [==>...........................] - ETA: 35s - loss: 1.3137 - accuracy: 0.615\n",
      "112/937 [==>...........................] - ETA: 35s - loss: 1.2534 - accuracy: 0.626\n",
      "127/937 [===>..........................] - ETA: 34s - loss: 1.1980 - accuracy: 0.643\n",
      "141/937 [===>..........................] - ETA: 33s - loss: 1.1534 - accuracy: 0.668\n",
      "155/937 [===>..........................] - ETA: 33s - loss: 1.1142 - accuracy: 0.671\n",
      "169/937 [====>.........................] - ETA: 32s - loss: 1.0791 - accuracy: 0.682\n",
      "183/937 [====>.........................] - ETA: 31s - loss: 1.0473 - accuracy: 0.692\n",
      "198/937 [=====>........................] - ETA: 31s - loss: 1.0167 - accuracy: 0.702\n",
      "212/937 [=====>........................] - ETA: 30s - loss: 0.9907 - accuracy: 0.710\n",
      "226/937 [======>.......................] - ETA: 30s - loss: 0.9670 - accuracy: 0.717\n",
      "240/937 [======>.......................] - ETA: 29s - loss: 0.9451 - accuracy: 0.724\n",
      "255/937 [=======>......................] - ETA: 28s - loss: 0.9233 - accuracy: 0.730\n",
      "269/937 [=======>......................] - ETA: 28s - loss: 0.9045 - accuracy: 0.737\n",
      "284/937 [========>.....................] - ETA: 27s - loss: 0.8858 - accuracy: 0.742\n",
      "296/937 [========>.....................] - ETA: 27s - loss: 0.8718 - accuracy: 0.747\n",
      "312/937 [========>.....................] - ETA: 26s - loss: 0.8543 - accuracy: 0.752\n",
      "326/937 [=========>....................] - ETA: 25s - loss: 0.8399 - accuracy: 0.756\n",
      "340/937 [=========>....................] - ETA: 25s - loss: 0.8263 - accuracy: 0.760\n",
      "354/937 [==========>...................] - ETA: 24s - loss: 0.8135 - accuracy: 0.764\n",
      "368/937 [==========>...................] - ETA: 24s - loss: 0.8013 - accuracy: 0.768\n",
      "382/937 [===========>..................] - ETA: 23s - loss: 0.7898 - accuracy: 0.771\n",
      "395/937 [===========>..................] - ETA: 22s - loss: 0.7796 - accuracy: 0.774\n",
      "409/937 [============>.................] - ETA: 22s - loss: 0.7691 - accuracy: 0.778\n",
      "423/937 [============>.................] - ETA: 21s - loss: 0.7590 - accuracy: 0.781\n",
      "436/937 [============>.................] - ETA: 21s - loss: 0.7501 - accuracy: 0.783\n",
      "451/937 [=============>................] - ETA: 20s - loss: 0.7403 - accuracy: 0.786\n",
      "465/937 [=============>................] - ETA: 20s - loss: 0.7316 - accuracy: 0.789\n",
      "481/937 [==============>...............] - ETA: 19s - loss: 0.7220 - accuracy: 0.791\n",
      "497/937 [==============>...............] - ETA: 18s - loss: 0.7129 - accuracy: 0.7949\n",
      "514/937 [===============>..............] - ETA: 17s - loss: 0.7037 - accuracy: 0.797\n",
      "531/937 [================>.............] - ETA: 16s - loss: 0.6948 - accuracy: 0.799\n",
      "548/937 [================>.............] - ETA: 16s - loss: 0.6864 - accuracy: 0.802\n",
      "566/937 [=================>............] - ETA: 15s - loss: 0.6778 - accuracy: 0.804\n",
      "583/937 [=================>............] - ETA: 14s - loss: 0.6700 - accuracy: 0.807\n",
      "600/937 [==================>...........] - ETA: 13s - loss: 0.6625 - accuracy: 0.809\n",
      "617/937 [==================>...........] - ETA: 13s - loss: 0.6553 - accuracy: 0.811\n",
      "634/937 [===================>..........] - ETA: 12s - loss: 0.6484 - accuracy: 0.813\n",
      "652/937 [===================>..........] - ETA: 11s - loss: 0.6414 - accuracy: 0.815\n",
      "667/937 [====================>.........] - ETA: 10s - loss: 0.6351 - accuracy: 0.817\n",
      "683/937 [====================>.........] - ETA: 10s - loss: 0.6306 - accuracy: 0.818\n",
      "701/937 [=====================>........] - ETA: 9s - loss: 0.6235 - accuracy: 0.8299\n",
      "718/937 [=====================>........] - ETA: 8s - loss: 0.6177 - accuracy: 0.82\n",
      "736/937 [======================>.......] - ETA: 7s - loss: 0.6117 - accuracy: 0.82\n",
      "753/937 [=======================>......] - ETA: 7s - loss: 0.6063 - accuracy: 0.82\n",
      "770/937 [=======================>......] - ETA: 6s - loss: 0.6010 - accuracy: 0.82\n",
      "785/937 [========================>.....] - ETA: 5s - loss: 0.5965 - accuracy: 0.82\n",
      "803/937 [========================>.....] - ETA: 5s - loss: 0.5912 - accuracy: 0.83\n",
      "821/937 [=========================>....] - ETA: 4s - loss: 0.5860 - accuracy: 0.83\n",
      "837/937 [=========================>....] - ETA: 3s - loss: 0.5816 - accuracy: 0.83\n",
      "855/937 [==========================>...] - ETA: 3s - loss: 0.5767 - accuracy: 0.83\n",
      "872/937 [==========================>...] - ETA: 2s - loss: 0.5723 - accuracy: 0.83\n",
      "892/937 [===========================>..] - ETA: 1s - loss: 0.5680 - accuracy: 0.83\n",
      "909/937 [============================>.] - ETA: 1s - loss: 0.5637 - accuracy: 0.83\n",
      "926/937 [============================>.] - ETA: 0s - loss: 0.5596 - accuracy: 0.83\n",
      "937/937 [==============================] - 60s 39ms/step - loss: 0.5560 - accuracy: 0.8407\n",
      "Epoch 2/3\n",
      " 14/937 [..............................] - ETA: 33s - loss: 0.2165 - accuracy: 0.9483\n",
      " 32/937 [>.............................] - ETA: 31s - loss: 0.2172 - accuracy: 0.941\n",
      " 46/937 [>.............................] - ETA: 31s - loss: 0.2154 - accuracy: 0.940\n",
      " 64/937 [=>............................] - ETA: 30s - loss: 0.2136 - accuracy: 0.939\n",
      " 81/937 [=>............................] - ETA: 29s - loss: 0.2122 - accuracy: 0.939\n",
      " 98/937 [==>...........................] - ETA: 29s - loss: 0.2117 - accuracy: 0.939\n",
      "115/937 [==>...........................] - ETA: 28s - loss: 0.2112 - accuracy: 0.939\n",
      "133/937 [===>..........................] - ETA: 27s - loss: 0.2097 - accuracy: 0.940\n",
      "151/937 [===>..........................] - ETA: 27s - loss: 0.2083 - accuracy: 0.940\n",
      "165/937 [====>.........................] - ETA: 26s - loss: 0.2074 - accuracy: 0.940\n",
      "183/937 [====>.........................] - ETA: 26s - loss: 0.2063 - accuracy: 0.940\n",
      "201/937 [=====>........................] - ETA: 25s - loss: 0.2053 - accuracy: 0.941\n",
      "219/937 [======>.......................] - ETA: 24s - loss: 0.2042 - accuracy: 0.941\n",
      "236/937 [======>.......................] - ETA: 24s - loss: 0.2032 - accuracy: 0.941\n",
      "255/937 [=======>......................] - ETA: 23s - loss: 0.2022 - accuracy: 0.942\n",
      "273/937 [=======>......................] - ETA: 22s - loss: 0.2013 - accuracy: 0.942\n",
      "290/937 [========>.....................] - ETA: 22s - loss: 0.2006 - accuracy: 0.942\n",
      "308/937 [========>.....................] - ETA: 21s - loss: 0.1999 - accuracy: 0.942\n",
      "326/937 [=========>....................] - ETA: 20s - loss: 0.1991 - accuracy: 0.942\n",
      "343/937 [=========>....................] - ETA: 20s - loss: 0.1985 - accuracy: 0.942\n",
      "361/937 [==========>...................] - ETA: 19s - loss: 0.1977 - accuracy: 0.943\n",
      "379/937 [===========>..................] - ETA: 19s - loss: 0.1970 - accuracy: 0.943\n",
      "396/937 [===========>..................] - ETA: 18s - loss: 0.1963 - accuracy: 0.943\n",
      "414/937 [============>.................] - ETA: 17s - loss: 0.1956 - accuracy: 0.943\n",
      "432/937 [============>.................] - ETA: 17s - loss: 0.1950 - accuracy: 0.943\n",
      "449/937 [=============>................] - ETA: 16s - loss: 0.1944 - accuracy: 0.943\n",
      "468/937 [=============>................] - ETA: 15s - loss: 0.1938 - accuracy: 0.944\n",
      "486/937 [==============>...............] - ETA: 15s - loss: 0.1933 - accuracy: 0.944\n",
      "504/937 [===============>..............] - ETA: 14s - loss: 0.1927 - accuracy: 0.944\n",
      "522/937 [===============>..............] - ETA: 14s - loss: 0.1922 - accuracy: 0.944\n",
      "540/937 [================>.............] - ETA: 13s - loss: 0.1917 - accuracy: 0.944\n",
      "558/937 [================>.............] - ETA: 12s - loss: 0.1912 - accuracy: 0.944\n",
      "576/937 [=================>............] - ETA: 12s - loss: 0.1907 - accuracy: 0.944\n",
      "595/937 [==================>...........] - ETA: 11s - loss: 0.1902 - accuracy: 0.944\n",
      "613/937 [==================>...........] - ETA: 10s - loss: 0.1897 - accuracy: 0.945\n",
      "631/937 [===================>..........] - ETA: 10s - loss: 0.1893 - accuracy: 0.945\n",
      "649/937 [===================>..........] - ETA: 9s - loss: 0.1888 - accuracy: 0.9455\n",
      "667/937 [====================>.........] - ETA: 9s - loss: 0.1884 - accuracy: 0.94\n",
      "685/937 [====================>.........] - ETA: 8s - loss: 0.1880 - accuracy: 0.94\n",
      "702/937 [=====================>........] - ETA: 7s - loss: 0.1877 - accuracy: 0.94\n",
      "720/937 [======================>.......] - ETA: 7s - loss: 0.1873 - accuracy: 0.94\n",
      "737/937 [======================>.......] - ETA: 6s - loss: 0.1869 - accuracy: 0.94\n",
      "755/937 [=======================>......] - ETA: 6s - loss: 0.1866 - accuracy: 0.94\n",
      "772/937 [=======================>......] - ETA: 5s - loss: 0.1862 - accuracy: 0.94\n",
      "793/937 [========================>.....] - ETA: 4s - loss: 0.1858 - accuracy: 0.94\n",
      "810/937 [========================>.....] - ETA: 4s - loss: 0.1854 - accuracy: 0.94\n",
      "828/937 [=========================>....] - ETA: 3s - loss: 0.1851 - accuracy: 0.94\n",
      "845/937 [==========================>...] - ETA: 3s - loss: 0.1847 - accuracy: 0.94\n",
      "863/937 [==========================>...] - ETA: 2s - loss: 0.1844 - accuracy: 0.94\n",
      "881/937 [===========================>..] - ETA: 1s - loss: 0.1840 - accuracy: 0.94\n",
      "899/937 [===========================>..] - ETA: 1s - loss: 0.1836 - accuracy: 0.94\n",
      "917/937 [============================>.] - ETA: 0s - loss: 0.1832 - accuracy: 0.94\n",
      "935/937 [============================>.] - ETA: 0s - loss: 0.1828 - accuracy: 0.946\n",
      "937/937 [==============================] - 32s 34ms/step - loss: 0.1828 - accuracy: 0.9468\n",
      "Epoch 3/3\n",
      " 15/937 [..............................] - ETA: 31s - loss: 0.1238 - accuracy: 0.964\n",
      " 32/937 [>.............................] - ETA: 31s - loss: 0.1226 - accuracy: 0.966\n",
      " 50/937 [>.............................] - ETA: 30s - loss: 0.1237 - accuracy: 0.966\n",
      " 68/937 [=>............................] - ETA: 29s - loss: 0.1237 - accuracy: 0.966\n",
      " 85/937 [=>............................] - ETA: 29s - loss: 0.1236 - accuracy: 0.966\n",
      "103/937 [==>...........................] - ETA: 28s - loss: 0.1232 - accuracy: 0.966\n",
      "121/937 [==>...........................] - ETA: 27s - loss: 0.1228 - accuracy: 0.966\n",
      "139/937 [===>..........................] - ETA: 27s - loss: 0.1228 - accuracy: 0.966\n",
      "156/937 [===>..........................] - ETA: 26s - loss: 0.1229 - accuracy: 0.965\n",
      "174/937 [====>.........................] - ETA: 25s - loss: 0.1230 - accuracy: 0.965\n",
      "192/937 [=====>........................] - ETA: 25s - loss: 0.1231 - accuracy: 0.965\n",
      "210/937 [=====>........................] - ETA: 24s - loss: 0.1232 - accuracy: 0.965\n",
      "228/937 [======>.......................] - ETA: 23s - loss: 0.1234 - accuracy: 0.965\n",
      "246/937 [======>.......................] - ETA: 23s - loss: 0.1236 - accuracy: 0.965\n",
      "263/937 [=======>......................] - ETA: 22s - loss: 0.1237 - accuracy: 0.965\n",
      "281/937 [=======>......................] - ETA: 22s - loss: 0.1238 - accuracy: 0.965\n",
      "298/937 [========>.....................] - ETA: 21s - loss: 0.1238 - accuracy: 0.964\n",
      "315/937 [=========>....................] - ETA: 21s - loss: 0.1239 - accuracy: 0.964\n",
      "332/937 [=========>....................] - ETA: 20s - loss: 0.1239 - accuracy: 0.964\n",
      "350/937 [==========>...................] - ETA: 19s - loss: 0.1238 - accuracy: 0.964\n",
      "367/937 [==========>...................] - ETA: 19s - loss: 0.1238 - accuracy: 0.964\n",
      "385/937 [===========>..................] - ETA: 18s - loss: 0.1237 - accuracy: 0.964\n",
      "402/937 [===========>..................] - ETA: 18s - loss: 0.1236 - accuracy: 0.964\n",
      "419/937 [============>.................] - ETA: 17s - loss: 0.1235 - accuracy: 0.964\n",
      "436/937 [============>.................] - ETA: 17s - loss: 0.1234 - accuracy: 0.964\n",
      "454/937 [=============>................] - ETA: 16s - loss: 0.1233 - accuracy: 0.964\n",
      "471/937 [==============>...............] - ETA: 15s - loss: 0.1233 - accuracy: 0.964\n",
      "489/937 [==============>...............] - ETA: 15s - loss: 0.1232 - accuracy: 0.964\n",
      "506/937 [===============>..............] - ETA: 14s - loss: 0.1231 - accuracy: 0.964\n",
      "523/937 [===============>..............] - ETA: 14s - loss: 0.1231 - accuracy: 0.964\n",
      "541/937 [================>.............] - ETA: 13s - loss: 0.1230 - accuracy: 0.964\n",
      "558/937 [================>.............] - ETA: 12s - loss: 0.1230 - accuracy: 0.964\n",
      "576/937 [=================>............] - ETA: 12s - loss: 0.1229 - accuracy: 0.964\n",
      "594/937 [==================>...........] - ETA: 11s - loss: 0.1229 - accuracy: 0.964\n",
      "612/937 [==================>...........] - ETA: 11s - loss: 0.1228 - accuracy: 0.964\n",
      "630/937 [===================>..........] - ETA: 10s - loss: 0.1227 - accuracy: 0.964\n",
      "648/937 [===================>..........] - ETA: 9s - loss: 0.1227 - accuracy: 0.9644\n",
      "666/937 [====================>.........] - ETA: 9s - loss: 0.1226 - accuracy: 0.964\n",
      "684/937 [====================>.........] - ETA: 8s - loss: 0.1225 - accuracy: 0.964\n",
      "702/937 [=====================>........] - ETA: 8s - loss: 0.1224 - accuracy: 0.964\n",
      "720/937 [======================>.......] - ETA: 7s - loss: 0.1223 - accuracy: 0.964\n",
      "738/937 [======================>.......] - ETA: 6s - loss: 0.1222 - accuracy: 0.964\n",
      "756/937 [=======================>......] - ETA: 6s - loss: 0.1221 - accuracy: 0.964\n",
      "772/937 [=======================>......] - ETA: 5s - loss: 0.1220 - accuracy: 0.964\n",
      "794/937 [========================>.....] - ETA: 4s - loss: 0.1219 - accuracy: 0.96\n",
      "812/937 [========================>.....] - ETA: 4s - loss: 0.1218 - accuracy: 0.96\n",
      "829/937 [=========================>....] - ETA: 3s - loss: 0.1218 - accuracy: 0.96\n",
      "847/937 [==========================>...] - ETA: 3s - loss: 0.1217 - accuracy: 0.96\n",
      "865/937 [==========================>...] - ETA: 2s - loss: 0.1216 - accuracy: 0.96\n",
      "882/937 [===========================>..] - ETA: 1s - loss: 0.1215 - accuracy: 0.96\n",
      "900/937 [===========================>..] - ETA: 1s - loss: 0.1215 - accuracy: 0.96\n",
      "917/937 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.96\n",
      "935/937 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 0.96\n",
      "937/937 [==============================] - 32s 34ms/step - loss: 0.1213 - accuracy: 0.9648\n",
      "2021-03-14 19:04:17.210660: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "\\ntraining_history: {'loss': [0.33556661009788513, 0.16377556324005127, 0.11752408742904663], 'accuracy': [0.9046324491500854, 0.9517076015472412, 0.9653648734092712]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<kubeflow.fairing.preprocessors.converted_notebook.ConvertNotebookPreprocessor at 0x7f8de7257940>,\n",
       " <kubeflow.fairing.builders.append.append.AppendBuilder at 0x7f8de72579e8>,\n",
       " <kubeflow.fairing.deployers.tfjob.tfjob.TfJob at 0x7f8de7257908>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kubeflow import fairing\n",
    "from kubeflow.fairing.kubernetes import utils as k8s_utils\n",
    "import uuid\n",
    "\n",
    "fairing.config.set_preprocessor(\n",
    "    'notebook', \n",
    "    notebook_file = 'mnist-dist.ipynb',\n",
    ")\n",
    "\n",
    "PRIVATE_REGISTRY = 'registry.kube-system.svc.cluster.local:30000'\n",
    "# base_image=f'{PRIVATE_REGISTRY}/mymnistbase'\n",
    "base_image='reddiana/mybase'\n",
    "fairing.config.set_builder(\n",
    "    'append',\n",
    "    base_image=base_image,\n",
    "    registry = PRIVATE_REGISTRY,\n",
    "    image_name='tfjob-fairing-mnist', \n",
    "    push=True,\n",
    ")\n",
    "\n",
    "fairing.config.set_deployer(\n",
    "    'tfjob',\n",
    "    # namespace='mysapce', # 생략 시 현재 노트북의 네임스페이스 사용\n",
    "    job_name=f'my-mnist-{uuid.uuid4().hex[:8]}',\n",
    "    chief_count=1, \n",
    "    worker_count=2,\n",
    "    pod_spec_mutators=[\n",
    "        # k8s_utils.mounting_pvc(pvc_name='mnist-tfjob-data-volume', pvc_mount_path='/data'),\n",
    "        k8s_utils.get_resource_mutator(cpu=0.5, memory=2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fairing.config.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "reddiana/jupyterlab-kale:0.0.9",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 210314 12:04:16 config:134] Using preprocessor: <kubeflow.fairing.preprocessors.base.BasePreProcessor object at 0x7f760de6b630>\n",
      "[I 210314 12:04:16 config:136] Using builder: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f760de6b6d8>\n",
      "[I 210314 12:04:16 config:138] Using deployer: <kubeflow.fairing.deployers.job.job.Job object at 0x7f760de6b668>\n",
      "[W 210314 12:04:16 append:50] Building image using Append builder...\n",
      "[I 210314 12:04:16 base:107] Creating docker context: /tmp/fairing_context_thh82pin\n",
      "[I 210314 12:04:16 docker_creds_:234] Loading Docker credentials for repository 'tensorflow/tensorflow'\n",
      "[W 210314 12:04:17 append:54] Image successfully built in 0.5099206780014356s.\n",
      "[W 210314 12:04:17 append:94] Pushing image registry.kube-system.svc.cluster.local:30000/my-02-python-file-fairing:90474E8B...\n",
      "[I 210314 12:04:17 docker_creds_:234] Loading Docker credentials for repository 'registry.kube-system.svc.cluster.local:30000/my-02-python-file-fairing:90474E8B'\n",
      "[W 210314 12:04:17 append:81] Uploading registry.kube-system.svc.cluster.local:30000/my-02-python-file-fairing:90474E8B\n",
      "[I 210314 12:04:17 docker_session_:280] Layer sha256:c29b15b084af0bc2cabab123e72a62f1d9919774f15a91eeeb3b138aaf5f7850 exists, skipping\n",
      "[I 210314 12:04:17 docker_session_:280] Layer sha256:b3afe92c540b778c64ca316d1e679d55d2d2e812e450f516a808ee591f0c3f77 exists, skipping\n",
      "[I 210314 12:04:17 docker_session_:280] Layer sha256:5d43e8c7056a20768e9c36d57ba56227f71df1563d630d424f512efd7b028805 exists, skipping\n",
      "[I 210314 12:04:17 docker_session_:280] Layer sha256:d22d2dfcfa9cd230ed3c47defec2670d45081598c721dd85cafc34ea459f970e exists, skipping\n",
      "[I 210314 12:04:17 docker_session_:280] Layer sha256:50fda3674ff59750d733018b8a5a24ebc8b42fd4b664981be65e57ee9d95c1fe exists, skipping\n",
      "[I 210314 12:04:17 docker_session_:280] Layer sha256:e266fced02fae9320dafe0ef2adab0fd0bdd5a7d795848c2fa344eafb4f70ab9 exists, skipping\n",
      "[I 210314 12:04:17 docker_session_:280] Layer sha256:c12ceea561ed13e6b0566ce331de9cfc90b43ab4b14a2e12a5a29d73420f51b3 exists, skipping\n",
      "[I 210314 12:04:17 docker_session_:280] Layer sha256:d519e2592276828ca171d85e0532899cd4f98c70f5c697b45fa2e126e9f9fe49 exists, skipping\n",
      "[I 210314 12:04:17 docker_session_:280] Layer sha256:961442e8e0e4f9ec91ef34f41523a3dc42e68476b5f8d27e2fe43f179d801263 exists, skipping\n",
      "[I 210314 12:04:17 docker_session_:280] Layer sha256:1f0ffb4d2509e58e040b2d3c146f875dfc5d39ac9e974e6bfb1a5505b98eefae exists, skipping\n",
      "[I 210314 12:04:17 docker_session_:280] Layer sha256:0b2b6f75fc9510d3889bb224823a6d8a720a0cba6d7481874e4612ccbccd3014 exists, skipping\n",
      "[I 210314 12:04:17 docker_session_:284] Layer sha256:9cd00af0dcf37b8f4a8f643750b631242480e4c095f1daeac9ccde9a1bb67d17 pushed.\n",
      "[I 210314 12:04:17 docker_session_:334] Finished upload of: registry.kube-system.svc.cluster.local:30000/my-02-python-file-fairing:90474E8B\n",
      "[W 210314 12:04:17 append:99] Pushed image registry.kube-system.svc.cluster.local:30000/my-02-python-file-fairing:90474E8B in 0.14779811999869708s.\n",
      "[W 210314 12:04:17 job:101] The job fairing-job-ph9st launched.\n",
      "[W 210314 12:04:17 manager:298] Waiting for fairing-job-ph9st-5w5f8 to start...\n",
      "[W 210314 12:04:17 manager:298] Waiting for fairing-job-ph9st-5w5f8 to start...\n",
      "[W 210314 12:04:17 manager:298] Waiting for fairing-job-ph9st-5w5f8 to start...\n",
      "[I 210314 12:04:19 manager:304] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-14 12:04:18.995557: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-03-14 12:04:18.995621: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "2021-03-14 12:04:21.863121: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-03-14 12:04:21.863476: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-03-14 12:04:21.863507: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-03-14 12:04:21.863534: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fairing-job-ph9st-5w5f8): /proc/driver/nvidia/version does not exist\n",
      "2021-03-14 12:04:21.864274: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-14 12:04:21.865782: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-03-14 12:04:22.043393: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 150528000 exceeds 10% of free system memory.\n",
      "2021-03-14 12:04:22.289854: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-03-14 12:04:22.290734: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #\n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0\n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480\n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0\n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290\n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/3\n",
      "  67/1500 [>.............................] - ETA: 10s - loss: 1.5913 - accuracy: 0.5166 \n",
      " 149/1500 [=>............................] - ETA: 9s - loss: 1.2439 - accuracy: 0.6306\n",
      " 231/1500 [===>..........................] - ETA: 9s - loss: 1.0651 - accuracy: 0.686\n",
      " 308/1500 [=====>........................] - ETA: 8s - loss: 0.9586 - accuracy: 0.719\n",
      " 399/1500 [======>.......................] - ETA: 7s - loss: 0.8689 - accuracy: 0.74\n",
      " 487/1500 [========>.....................] - ETA: 7s - loss: 0.8052 - accuracy: 0.76\n",
      " 575/1500 [==========>...................] - ETA: 6s - loss: 0.7632 - accuracy: 0.77\n",
      " 653/1500 [============>.................] - ETA: 5s - loss: 0.7261 - accuracy: 0.78\n",
      " 742/1500 [=============>................] - ETA: 5s - loss: 0.6895 - accuracy: 0.80\n",
      " 832/1500 [===============>..............] - ETA: 4s - loss: 0.6597 - accuracy: 0.80\n",
      " 908/1500 [=================>............] - ETA: 4s - loss: 0.6338 - accuracy: 0.81\n",
      " 998/1500 [==================>...........] - ETA: 3s - loss: 0.6116 - accuracy: 0.82\n",
      "1088/1500 [====================>.........] - ETA: 2s - loss: 0.5920 - accuracy: 0.82\n",
      "1177/1500 [======================>.......] - ETA: 2s - loss: 0.5746 - accuracy: 0.83\n",
      "1274/1500 [========================>.....] - ETA: 1s - loss: 0.5576 - accuracy: 0.83\n",
      "1367/1500 [==========================>...] - ETA: 0s - loss: 0.5428 - accuracy: 0.84\n",
      "1464/1500 [============================>.] - ETA: 0s - loss: 0.5287 - accuracy: 0.8470\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.5237 - accuracy: 0.8484 - val_loss: 0.1588 - val_accuracy: 0.9563\n",
      "Epoch 2/3\n",
      "  66/1500 [>.............................] - ETA: 10s - loss: 0.1964 - accuracy: 0.938\n",
      " 163/1500 [==>...........................] - ETA: 8s - loss: 0.1862 - accuracy: 0.9429\n",
      " 256/1500 [====>.........................] - ETA: 8s - loss: 0.1846 - accuracy: 0.942\n",
      " 349/1500 [=====>........................] - ETA: 7s - loss: 0.1843 - accuracy: 0.942\n",
      " 448/1500 [=======>......................] - ETA: 6s - loss: 0.1829 - accuracy: 0.943\n",
      " 539/1500 [=========>....................] - ETA: 6s - loss: 0.1814 - accuracy: 0.94\n",
      " 616/1500 [===========>..................] - ETA: 5s - loss: 0.1804 - accuracy: 0.94\n",
      " 708/1500 [=============>................] - ETA: 5s - loss: 0.1793 - accuracy: 0.94\n",
      " 803/1500 [===============>..............] - ETA: 4s - loss: 0.1781 - accuracy: 0.94\n",
      " 895/1500 [================>.............] - ETA: 3s - loss: 0.1770 - accuracy: 0.94\n",
      " 981/1500 [==================>...........] - ETA: 3s - loss: 0.1760 - accuracy: 0.94\n",
      "1040/1500 [===================>..........] - ETA: 2s - loss: 0.1754 - accuracy: 0.94\n",
      "1134/1500 [=====================>........] - ETA: 2s - loss: 0.1746 - accuracy: 0.94\n",
      "1217/1500 [=======================>......] - ETA: 1s - loss: 0.1740 - accuracy: 0.94\n",
      "1312/1500 [=========================>....] - ETA: 1s - loss: 0.1732 - accuracy: 0.94\n",
      "1375/1500 [==========================>...] - ETA: 0s - loss: 0.1726 - accuracy: 0.94\n",
      "1442/1500 [===========================>..] - ETA: 0s - loss: 0.1720 - accuracy: 0.94\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.1715 - accuracy: 0.9475 - val_loss: 0.1194 - val_accuracy: 0.9652\n",
      "Epoch 3/3\n",
      "  74/1500 [>.............................] - ETA: 9s - loss: 0.1044 - accuracy: 0.96\n",
      " 161/1500 [==>...........................] - ETA: 9s - loss: 0.1100 - accuracy: 0.96\n",
      " 255/1500 [====>.........................] - ETA: 8s - loss: 0.1127 - accuracy: 0.96\n",
      " 351/1500 [======>.......................] - ETA: 7s - loss: 0.1144 - accuracy: 0.96\n",
      " 427/1500 [=======>......................] - ETA: 7s - loss: 0.1161 - accuracy: 0.96\n",
      " 523/1500 [=========>....................] - ETA: 6s - loss: 0.1178 - accuracy: 0.96\n",
      " 619/1500 [===========>..................] - ETA: 5s - loss: 0.1187 - accuracy: 0.96\n",
      " 716/1500 [=============>................] - ETA: 5s - loss: 0.1192 - accuracy: 0.96\n",
      " 814/1500 [===============>..............] - ETA: 4s - loss: 0.1196 - accuracy: 0.96\n",
      " 906/1500 [=================>............] - ETA: 3s - loss: 0.1199 - accuracy: 0.96\n",
      "1004/1500 [==================>...........] - ETA: 3s - loss: 0.1201 - accuracy: 0.96\n",
      "1097/1500 [====================>.........] - ETA: 2s - loss: 0.1202 - accuracy: 0.96\n",
      "1174/1500 [======================>.......] - ETA: 2s - loss: 0.1203 - accuracy: 0.963\n",
      "1268/1500 [========================>.....] - ETA: 1s - loss: 0.1204 - accuracy: 0.963\n",
      "1360/1500 [==========================>...] - ETA: 0s - loss: 0.1205 - accuracy: 0.963\n",
      "1454/1500 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.963\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.1205 - accuracy: 0.9638 - val_loss: 0.1005 - val_accuracy: 0.9732\n",
      "Test accuracy:  0.9728000164031982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 210314 12:04:57 job:173] Cleaning up job fairing-job-ph9st...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<kubeflow.fairing.preprocessors.base.BasePreProcessor at 0x7f760de6b630>,\n",
       " <kubeflow.fairing.builders.append.append.AppendBuilder at 0x7f760de6b6d8>,\n",
       " <kubeflow.fairing.deployers.job.job.Job at 0x7f760de6b668>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kubeflow import fairing\n",
    "from kubeflow.fairing.kubernetes import utils as k8s_utils\n",
    "\n",
    "PRIVATE_REGISTRY = 'registry.kube-system.svc.cluster.local:30000'\n",
    "\n",
    "fairing.config.set_preprocessor(\n",
    "    'python', \n",
    "     # command = ['python'],  # default: python\n",
    "     input_files = ['00-python-file-to-fairing.py'], # 생성되는 image의 /app/ 디렉토리로 복사됨\n",
    ")\n",
    "\n",
    "fairing.config.set_builder(\n",
    "    'append',\n",
    "    base_image = 'tensorflow/tensorflow',\n",
    "    registry = PRIVATE_REGISTRY,\n",
    "    image_name='my-02-python-file-fairing', \n",
    "    push=True\n",
    ")\n",
    "\n",
    "fairing.config.set_deployer(\n",
    "    'job',\n",
    "    # namespace='myspace', # default: 현재 네임스페이스\n",
    "    pod_spec_mutators=[\n",
    "        k8s_utils.get_resource_mutator(cpu=1, memory=5)]\n",
    ")\n",
    "\n",
    "fairing.config.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Image 확인\n",
    "- Host에서 실행\n",
    "- fairing에서 난수로 생성한 tag를 변경해서 실행할 것 (예: E2683407)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Image pull\n",
    "```sh\n",
    "docker pull registry.kube-system.svc.cluster.local:30000/my-02-python-file-fairing:E2683407\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Image inspect\n",
    "```sh\n",
    "docker inspect registry.kube-system.svc.cluster.local:30000/my-02-python-file-fairing:E2683407\n",
    "```\n",
    "Cmd 항목을 확인하고 faring 코드대로 image build 되었음을 확인\n",
    "```json\n",
    "...\n",
    "            \"Cmd\": [\n",
    "                \"python\",\n",
    "                \"/app/00-python-file-to-fairing.py\"\n",
    "            ],\n",
    "...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "reddiana/jupyterlab-kale:0.0.9",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

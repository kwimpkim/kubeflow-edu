{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 210114 09:45:36 config:134] Using preprocessor: <kubeflow.fairing.preprocessors.converted_notebook.ConvertNotebookPreprocessor object at 0x7f57514642e8>\n",
      "[I 210114 09:45:36 config:136] Using builder: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f5751464c88>\n",
      "[I 210114 09:45:36 config:138] Using deployer: <kubeflow.fairing.deployers.job.job.Job object at 0x7f5751464e10>\n",
      "[W 210114 09:45:36 append:50] Building image using Append builder...\n",
      "[I 210114 09:45:36 base:107] Creating docker context: /tmp/fairing_context_7ly5c09w\n",
      "[I 210114 09:45:36 converted_notebook:127] Converting 02-A-notebook-to-fairing.ipynb to 02-A-notebook-to-fairing.py\n",
      "[I 210114 09:45:36 docker_creds_:234] Loading Docker credentials for repository 'tensorflow/tensorflow:2.0.3-gpu-py3'\n",
      "[W 210114 09:45:38 append:54] Image successfully built in 2.0979556040001626s.\n",
      "[W 210114 09:45:38 append:94] Pushing image kubeflow-registry.default.svc.cluster.local:30000/my-03-notebook-fairing-job:AFF548C...\n",
      "[I 210114 09:45:38 docker_creds_:234] Loading Docker credentials for repository 'kubeflow-registry.default.svc.cluster.local:30000/my-03-notebook-fairing-job:AFF548C'\n",
      "[W 210114 09:45:38 append:81] Uploading kubeflow-registry.default.svc.cluster.local:30000/my-03-notebook-fairing-job:AFF548C\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:d69f906e5daf636062d23a04229abd5ad7cc9dc4ed4fec747209c475d2baedbe exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:808ab635d662f007795c47a50aa04f09645f4ff2356cb3b4a4793dc849f8c567 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:b11f037be8e82a958bc0f85b0fa2a73515ce8954042eac96bb654e662ae9519f exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:3baa9cb2483bd9c5329a44d9c2fe72535625bbd4308bca95785dd58e72c06365 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:a6b0136f4b734fa962c4f6a51536f4c66bdf70607e08a815cc8b1ee28b967af7 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:8ed3cb4f3e640b8c622e61beba1b83f115f32756055cafcc5840e4ae4f806cab exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:05cc64cc481fe79962b34513eab815d88ebe4ac6ac5014f5a75059120ff54403 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:eee182b1b1f319aa543a64cf31d2ab0479870a7dc103da35ad4e450513dccdb9 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:070a62d3637f8c595c077236428e31730dc98014b41d0b15428eb55f3fca795f exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:f24e58c7d76b40e220b929eb26738ea454d26e69b3c4f69915dbc39d801ad2bb exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:180a91d332525099dc19822a6acdd951afc8caa017d5101cfe925d839a86d806 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:64c1fb90b5a5b52bc9cd212302432b449b17377ab2822b7df3bf51183f955a15 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:f08d8e2a3ba11bea23cf5c17e8e1c620057412ed05c32d1114640e18d6dd0a43 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:94e5ff4c0b1526abf77c236655f21c8f67a23313291c8b970fe6b469549d8153 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:da612ad945dfc0bddf4057d29e35c73c95bb864754567ab5068fe7b1fbd8b696 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:24379c211bf57a28dc199d0b1e7dc6a8055c42367f7dc7aa7af94233424320d0 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:280] Layer sha256:1860925334f940c3145808527480b4f0cba7f01279087fdb27679e4354fba967 exists, skipping\n",
      "[I 210114 09:45:38 docker_session_:284] Layer sha256:8a212b6f061d4c975faff14ed91972f6da36b36b364faf2ca4ff1ecbe16a5d93 pushed.\n",
      "[I 210114 09:45:38 docker_session_:334] Finished upload of: kubeflow-registry.default.svc.cluster.local:30000/my-03-notebook-fairing-job:AFF548C\n",
      "[W 210114 09:45:38 append:99] Pushed image kubeflow-registry.default.svc.cluster.local:30000/my-03-notebook-fairing-job:AFF548C in 0.12221980499998608s.\n",
      "[W 210114 09:45:38 job:101] The job fairing-job-l2r6v launched.\n",
      "[W 210114 09:45:38 manager:298] Waiting for fairing-job-l2r6v-24845 to start...\n",
      "[W 210114 09:45:38 manager:298] Waiting for fairing-job-l2r6v-24845 to start...\n",
      "[W 210114 09:45:38 manager:298] Waiting for fairing-job-l2r6v-24845 to start...\n",
      "[I 210114 09:45:40 manager:304] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "2021-01-14 09:45:42.794257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-01-14 09:45:42.794323: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (-1)\n",
      "2021-01-14 09:45:42.794367: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fairing-job-l2r6v-24845): /proc/driver/nvidia/version does not exist\n",
      "2021-01-14 09:45:42.794732: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-01-14 09:45:42.803971: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2021-01-14 09:45:42.804954: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2937470 executing computations on platform Host. Devices:\n",
      "2021-01-14 09:45:42.804999: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2021-01-14 09:45:42.959844: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 301056000 exceeds 10% of system memory.\n",
      "2021-01-14 09:45:43.297770: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 75264000 exceeds 10% of system memory.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #\n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0\n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480\n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0\n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290\n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      " 2400/48000 [>.............................] - ETA: 19s - loss: 1.1425 - accuracy: 0.67213\n",
      " 5536/48000 [==>...........................] - ETA: 12s - loss: 0.7882 - accuracy: 0.766\n",
      " 8736/48000 [====>.........................] - ETA: 10s - loss: 0.6622 - accuracy: 0.810\n",
      "11520/48000 [======>.......................] - ETA: 8s - loss: 0.5766 - accuracy: 0.838\n",
      "14848/48000 [========>.....................] - ETA: 7s - loss: 0.5214 - accuracy: 0.84\n",
      "18208/48000 [==========>...................] - ETA: 6s - loss: 0.4793 - accuracy: 0.86\n",
      "21600/48000 [============>.................] - ETA: 5s - loss: 0.4528 - accuracy: 0.86\n",
      "24922/48000 [==============>...............] - ETA: 4s - loss: 0.4263 - accuracy: 0.87\n",
      "27616/48000 [================>.............] - ETA: 4s - loss: 0.4049 - accuracy: 0.881\n",
      "30848/48000 [==================>...........] - ETA: 3s - loss: 0.3892 - accuracy: 0.886\n",
      "34240/48000 [====================>.........] - ETA: 2s - loss: 0.3769 - accuracy: 0.89\n",
      "37696/48000 [======================>.......] - ETA: 2s - loss: 0.3626 - accuracy: 0.89\n",
      "40544/48000 [========================>.....] - ETA: 1s - loss: 0.3489 - accuracy: 0.89\n",
      "44096/48000 [==========================>...] - ETA: 0s - loss: 0.3378 - accuracy: 0.90\n",
      "47584/48000 [============================>.] - ETA: 0s - loss: 0.3268 - accuracy: 0.90\n",
      "48000/48000 [==============================] - 11s 220us/sample - loss: 0.3259 - accuracy: 0.9049 - val_loss: 0.1614 - val_accuracy: 0.9533\n",
      "Epoch 2/3\n",
      " 2656/48000 [>.............................] - ETA: 8s - loss: 0.1716 - accuracy: 0.94\n",
      " 5760/48000 [==>...........................] - ETA: 7s - loss: 0.1690 - accuracy: 0.95\n",
      " 8832/48000 [====>.........................] - ETA: 7s - loss: 0.1727 - accuracy: 0.94\n",
      "12288/48000 [======>.......................] - ETA: 6s - loss: 0.1674 - accuracy: 0.95\n",
      "15264/48000 [========>.....................] - ETA: 5s - loss: 0.1697 - accuracy: 0.950\n",
      "18784/48000 [==========>...................] - ETA: 5s - loss: 0.1694 - accuracy: 0.949\n",
      "22336/48000 [============>.................] - ETA: 4s - loss: 0.1695 - accuracy: 0.949\n",
      "25920/48000 [===============>..............] - ETA: 3s - loss: 0.1690 - accuracy: 0.94\n",
      "29376/48000 [=================>............] - ETA: 3s - loss: 0.1680 - accuracy: 0.95\n",
      "32224/48000 [===================>..........] - ETA: 2s - loss: 0.1655 - accuracy: 0.95\n",
      "35680/48000 [=====================>........] - ETA: 2s - loss: 0.1650 - accuracy: 0.95\n",
      "39136/48000 [=======================>......] - ETA: 1s - loss: 0.1638 - accuracy: 0.95\n",
      "42624/48000 [=========================>....] - ETA: 1s - loss: 0.1618 - accuracy: 0.95\n",
      "45504/48000 [===========================>..] - ETA: 0s - loss: 0.1609 - accuracy: 0.952\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.1584 - accuracy: 0.9527 - val_loss: 0.1154 - val_accuracy: 0.9673\n",
      "Epoch 3/3\n",
      " 2400/48000 [>.............................] - ETA: 8s - loss: 0.1218 - accuracy: 0.9609\n",
      " 5728/48000 [==>...........................] - ETA: 7s - loss: 0.1184 - accuracy: 0.962\n",
      " 9088/48000 [====>.........................] - ETA: 7s - loss: 0.1253 - accuracy: 0.96\n",
      "12544/48000 [======>.......................] - ETA: 6s - loss: 0.1241 - accuracy: 0.96\n",
      "15456/48000 [========>.....................] - ETA: 5s - loss: 0.1250 - accuracy: 0.96\n",
      "18880/48000 [==========>...................] - ETA: 5s - loss: 0.1260 - accuracy: 0.96\n",
      "22240/48000 [============>.................] - ETA: 4s - loss: 0.1259 - accuracy: 0.96\n",
      "25632/48000 [===============>..............] - ETA: 4s - loss: 0.1248 - accuracy: 0.96\n",
      "28960/48000 [================>.............] - ETA: 3s - loss: 0.1234 - accuracy: 0.96\n",
      "31872/48000 [==================>...........] - ETA: 2s - loss: 0.1228 - accuracy: 0.962\n",
      "35424/48000 [=====================>........] - ETA: 2s - loss: 0.1219 - accuracy: 0.963\n",
      "38912/48000 [=======================>......] - ETA: 1s - loss: 0.1212 - accuracy: 0.96\n",
      "42400/48000 [=========================>....] - ETA: 1s - loss: 0.1213 - accuracy: 0.96\n",
      "45312/48000 [===========================>..] - ETA: 0s - loss: 0.1206 - accuracy: 0.96\n",
      "48000/48000 [==============================] - 10s 200us/sample - loss: 0.1204 - accuracy: 0.9635 - val_loss: 0.0971 - val_accuracy: 0.9712\n",
      "2021-01-14 09:46:13.062508: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 62720000 exceeds 10% of system memory.\n",
      "Test accuracy:  0.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 210114 09:46:14 job:173] Cleaning up job fairing-job-l2r6v...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<kubeflow.fairing.preprocessors.converted_notebook.ConvertNotebookPreprocessor at 0x7f57514642e8>,\n",
       " <kubeflow.fairing.builders.append.append.AppendBuilder at 0x7f5751464c88>,\n",
       " <kubeflow.fairing.deployers.job.job.Job at 0x7f5751464e10>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kubeflow import fairing\n",
    "from kubeflow.fairing.kubernetes import utils as k8s_utils\n",
    "\n",
    "PRIVATE_REGISTRY = 'kubeflow-registry.default.svc.cluster.local:30000'\n",
    "\n",
    "fairing.config.set_preprocessor(\n",
    "    'notebook', \n",
    "    notebook_file = '02-A-notebook-to-fairing.ipynb'\n",
    ")\n",
    "\n",
    "fairing.config.set_builder(\n",
    "    'append',\n",
    "    # base_image = f'{PRIVATE_REGISTRY}/kf-base:latest', # 사전준비에서 마련한 Base Image\n",
    "    base_image = 'tensorflow/tensorflow:2.0.3-gpu-py3',\n",
    "    registry = PRIVATE_REGISTRY,\n",
    "    image_name='my-03-notebook-fairing-job', \n",
    "    push=True\n",
    ")\n",
    "\n",
    "fairing.config.set_deployer(\n",
    "    'job',\n",
    "    namespace='myspace',\n",
    "    pod_spec_mutators=[\n",
    "        k8s_utils.get_resource_mutator(cpu=1, memory=5)]\n",
    ")\n",
    "\n",
    "fairing.config.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "reddiana/jupyterlab-kale:0.0.9",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
